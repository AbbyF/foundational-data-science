<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Foundational Data Science</title>
  <meta name="description" content="This course provides a firm foundation on the fundamentals of data science using R, with a focus on key statistical methods, exploratory data analysis, and visualizations. Before worrying about advanced analytics and neural nets, it is important to master the core skills. While this is certainly not a mathematical course, we won’t shy away from giving insight into the underlying mathematical theory.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Foundational Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://csgillespie.github.io/foundational-data-science/" />
  
  <meta property="og:description" content="This course provides a firm foundation on the fundamentals of data science using R, with a focus on key statistical methods, exploratory data analysis, and visualizations. Before worrying about advanced analytics and neural nets, it is important to master the core skills. While this is certainly not a mathematical course, we won’t shy away from giving insight into the underlying mathematical theory." />
  <meta name="github-repo" content="csgillespie/foundational-data-science" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Foundational Data Science" />
  <meta name="twitter:site" content="@csgillespie" />
  <meta name="twitter:description" content="This course provides a firm foundation on the fundamentals of data science using R, with a focus on key statistical methods, exploratory data analysis, and visualizations. Before worrying about advanced analytics and neural nets, it is important to master the core skills. While this is certainly not a mathematical course, we won’t shy away from giving insight into the underlying mathematical theory." />
  

<meta name="author" content="Colin Gillespie">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chapter4.html">
<link rel="next" href="chapter6.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Foundational Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Author</a></li>
<li class="chapter" data-level="1" data-path="chapter1.html"><a href="chapter1.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="chapter1.html"><a href="chapter1.html#book-overview"><i class="fa fa-check"></i><b>1.1</b> Book overview</a><ul>
<li class="chapter" data-level="1.1.1" data-path="chapter1.html"><a href="chapter1.html#the-trouble-with-tibbles-data"><i class="fa fa-check"></i><b>1.1.1</b> The trouble with <del>tibbles</del> data</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="chapter1.html"><a href="chapter1.html#talking-about-data"><i class="fa fa-check"></i><b>1.2</b> Talking about data</a><ul>
<li class="chapter" data-level="1.2.1" data-path="chapter1.html"><a href="chapter1.html#sample-size"><i class="fa fa-check"></i><b>1.2.1</b> Sample size</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="chapter1.html"><a href="chapter1.html#designing-the-experiment"><i class="fa fa-check"></i><b>1.3</b> Designing the experiment</a></li>
<li class="chapter" data-level="1.4" data-path="chapter1.html"><a href="chapter1.html#data-sets"><i class="fa fa-check"></i><b>1.4</b> Data sets</a><ul>
<li class="chapter" data-level="1.4.1" data-path="chapter1.html"><a href="chapter1.html#the-relationship-between-beauty-and-teaching"><i class="fa fa-check"></i><b>1.4.1</b> The relationship between beauty and teaching</a></li>
<li class="chapter" data-level="1.4.2" data-path="chapter1.html"><a href="chapter1.html#bond-james-bond"><i class="fa fa-check"></i><b>1.4.2</b> Bond, James Bond</a></li>
<li class="chapter" data-level="1.4.3" data-path="chapter1.html"><a href="chapter1.html#okcupid"><i class="fa fa-check"></i><b>1.4.3</b> OKCupid</a></li>
<li class="chapter" data-level="1.4.4" data-path="chapter1.html"><a href="chapter1.html#starbucks"><i class="fa fa-check"></i><b>1.4.4</b> Starbucks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> Condensing data with numerical summaries</a><ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#mathematical-notation"><i class="fa fa-check"></i><b>2.1</b> Mathematical notation</a></li>
<li class="chapter" data-level="2.2" data-path="chapter2.html"><a href="chapter2.html#measures-of-location"><i class="fa fa-check"></i><b>2.2</b> Measures of location</a><ul>
<li class="chapter" data-level="2.2.1" data-path="chapter2.html"><a href="chapter2.html#sample-mean"><i class="fa fa-check"></i><b>2.2.1</b> Sample mean</a></li>
<li class="chapter" data-level="" data-path="chapter2.html"><a href="chapter2.html#example-the-beauty-data-set"><i class="fa fa-check"></i>Example: The beauty data set</a></li>
<li class="chapter" data-level="2.2.2" data-path="chapter2.html"><a href="chapter2.html#sample-median"><i class="fa fa-check"></i><b>2.2.2</b> Sample median</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="chapter2.html"><a href="chapter2.html#measures-of-spread"><i class="fa fa-check"></i><b>2.3</b> Measures of spread</a><ul>
<li class="chapter" data-level="2.3.1" data-path="chapter2.html"><a href="chapter2.html#range"><i class="fa fa-check"></i><b>2.3.1</b> Range</a></li>
<li class="chapter" data-level="2.3.2" data-path="chapter2.html"><a href="chapter2.html#sample-variance-and-standard-deviation"><i class="fa fa-check"></i><b>2.3.2</b> Sample variance and standard deviation</a></li>
<li class="chapter" data-level="2.3.3" data-path="chapter2.html"><a href="chapter2.html#quartiles-and-the-interquartile-range"><i class="fa fa-check"></i><b>2.3.3</b> Quartiles and the interquartile range</a></li>
<li class="chapter" data-level="2.3.4" data-path="chapter2.html"><a href="chapter2.html#numerical-examples"><i class="fa fa-check"></i><b>2.3.4</b> Numerical examples</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="chapter2.html"><a href="chapter2.html#streaming-data"><i class="fa fa-check"></i><b>2.4</b> Streaming data</a><ul>
<li class="chapter" data-level="2.4.1" data-path="chapter2.html"><a href="chapter2.html#the-mean-and-variance"><i class="fa fa-check"></i><b>2.4.1</b> The mean and variance</a></li>
<li class="chapter" data-level="2.4.2" data-path="chapter2.html"><a href="chapter2.html#the-median-and-quantiles"><i class="fa fa-check"></i><b>2.4.2</b> The median and quantiles</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="chapter2.html"><a href="chapter2.html#relevant-r-functions"><i class="fa fa-check"></i>Relevant R functions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> What, why and how of visualisation</a><ul>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#historical-visualisations"><i class="fa fa-check"></i><b>3.1</b> Historical visualisations</a></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#scatter-plots"><i class="fa fa-check"></i><b>3.2</b> Scatter plots</a><ul>
<li class="chapter" data-level="3.2.1" data-path="chapter3.html"><a href="chapter3.html#styling-your-plot"><i class="fa fa-check"></i><b>3.2.1</b> Styling your plot</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="chapter3.html"><a href="chapter3.html#histograms"><i class="fa fa-check"></i><b>3.3</b> Histograms</a></li>
<li class="chapter" data-level="3.4" data-path="chapter3.html"><a href="chapter3.html#density-plots"><i class="fa fa-check"></i><b>3.4</b> Density plots</a><ul>
<li class="chapter" data-level="3.4.1" data-path="chapter3.html"><a href="chapter3.html#detailed-explanation"><i class="fa fa-check"></i><b>3.4.1</b> Detailed explanation</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="chapter3.html"><a href="chapter3.html#boxplots"><i class="fa fa-check"></i><b>3.5</b> Boxplots</a></li>
<li class="chapter" data-level="3.6" data-path="chapter3.html"><a href="chapter3.html#barplots"><i class="fa fa-check"></i><b>3.6</b> Barplots</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter4.html"><a href="chapter4.html"><i class="fa fa-check"></i><b>4</b> The normal distribution - what’s the point?</a><ul>
<li class="chapter" data-level="4.1" data-path="chapter4.html"><a href="chapter4.html#the-bernoulli-distribution"><i class="fa fa-check"></i><b>4.1</b> The Bernoulli distribution</a><ul>
<li class="chapter" data-level="4.1.1" data-path="chapter4.html"><a href="chapter4.html#motivating-example"><i class="fa fa-check"></i><b>4.1.1</b> Motivating example</a></li>
<li class="chapter" data-level="4.1.2" data-path="chapter4.html"><a href="chapter4.html#description"><i class="fa fa-check"></i><b>4.1.2</b> Description</a></li>
<li class="chapter" data-level="4.1.3" data-path="chapter4.html"><a href="chapter4.html#example"><i class="fa fa-check"></i><b>4.1.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="chapter4.html"><a href="chapter4.html#the-binomial-distribution"><i class="fa fa-check"></i><b>4.2</b> The Binomial distribution</a><ul>
<li class="chapter" data-level="4.2.1" data-path="chapter4.html"><a href="chapter4.html#motivating-example-1"><i class="fa fa-check"></i><b>4.2.1</b> Motivating example</a></li>
<li class="chapter" data-level="4.2.2" data-path="chapter4.html"><a href="chapter4.html#description-1"><i class="fa fa-check"></i><b>4.2.2</b> Description</a></li>
<li class="chapter" data-level="4.2.3" data-path="chapter4.html"><a href="chapter4.html#what-does-the-binomial-distribution-look-like"><i class="fa fa-check"></i><b>4.2.3</b> What does the Binomial distribution look like?</a></li>
<li class="chapter" data-level="4.2.4" data-path="chapter4.html"><a href="chapter4.html#motivating-example-2"><i class="fa fa-check"></i><b>4.2.4</b> Motivating example</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="chapter4.html"><a href="chapter4.html#the-normalgaussian-distribution"><i class="fa fa-check"></i><b>4.3</b> The Normal/Gaussian distribution</a><ul>
<li class="chapter" data-level="4.3.1" data-path="chapter4.html"><a href="chapter4.html#continuous-and-discrete-distributions"><i class="fa fa-check"></i><b>4.3.1</b> Continuous and discrete distributions</a></li>
<li class="chapter" data-level="4.3.2" data-path="chapter4.html"><a href="chapter4.html#the-standard-deviations-rule"><i class="fa fa-check"></i><b>4.3.2</b> The standard deviations rule</a></li>
<li class="chapter" data-level="4.3.3" data-path="chapter4.html"><a href="chapter4.html#the-z-score"><i class="fa fa-check"></i><b>4.3.3</b> The Z-Score</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter5.html"><a href="chapter5.html"><i class="fa fa-check"></i><b>5</b> Margin of Error</a><ul>
<li class="chapter" data-level="5.1" data-path="chapter5.html"><a href="chapter5.html#introduction-motativating-example"><i class="fa fa-check"></i><b>5.1</b> Introduction &amp; motativating example</a></li>
<li class="chapter" data-level="5.2" data-path="chapter5.html"><a href="chapter5.html#one-sample-test"><i class="fa fa-check"></i><b>5.2</b> One sample test</a><ul>
<li class="chapter" data-level="5.2.1" data-path="chapter5.html"><a href="chapter5.html#example-okcupid-1"><i class="fa fa-check"></i><b>5.2.1</b> Example: OKCupid</a></li>
<li class="chapter" data-level="5.2.2" data-path="chapter5.html"><a href="chapter5.html#errors"><i class="fa fa-check"></i><b>5.2.2</b> Errors</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="chapter5.html"><a href="chapter5.html#two-sample-z-test"><i class="fa fa-check"></i><b>5.3</b> Two sample z-test</a></li>
<li class="chapter" data-level="5.4" data-path="chapter5.html"><a href="chapter5.html#confidence-intervals"><i class="fa fa-check"></i><b>5.4</b> Confidence intervals</a><ul>
<li class="chapter" data-level="5.4.1" data-path="chapter5.html"><a href="chapter5.html#construction"><i class="fa fa-check"></i><b>5.4.1</b> Construction</a></li>
<li class="chapter" data-level="5.4.2" data-path="chapter5.html"><a href="chapter5.html#example-comic-sans"><i class="fa fa-check"></i><b>5.4.2</b> Example: Comic Sans</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="chapter5.html"><a href="chapter5.html#the-central-limit-therem-clt"><i class="fa fa-check"></i><b>5.5</b> The Central Limit Therem (CLT)</a><ul>
<li class="chapter" data-level="5.5.1" data-path="chapter5.html"><a href="chapter5.html#example-customer-waiting-times"><i class="fa fa-check"></i><b>5.5.1</b> Example: Customer waiting times</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter6.html"><a href="chapter6.html"><i class="fa fa-check"></i><b>6</b> Capturing relationships with linear regression</a><ul>
<li class="chapter" data-level="6.1" data-path="chapter6.html"><a href="chapter6.html#capturing-linear-relationships"><i class="fa fa-check"></i><b>6.1</b> Capturing linear relationships</a><ul>
<li class="chapter" data-level="6.1.1" data-path="chapter6.html"><a href="chapter6.html#example-starbucks-calorie-content"><i class="fa fa-check"></i><b>6.1.1</b> Example: Starbucks calorie content</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="chapter6.html"><a href="chapter6.html#linear-regression"><i class="fa fa-check"></i><b>6.2</b> Linear Regression</a><ul>
<li class="chapter" data-level="6.2.1" data-path="chapter6.html"><a href="chapter6.html#prediction-and-interpretation"><i class="fa fa-check"></i><b>6.2.1</b> Prediction and Interpretation</a></li>
<li class="chapter" data-level="6.2.2" data-path="chapter6.html"><a href="chapter6.html#how-do-we-estimate-the-model-coefficients"><i class="fa fa-check"></i><b>6.2.2</b> How do we estimate the model coefficients?</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="chapter6.html"><a href="chapter6.html#multiple-linear-regression-models"><i class="fa fa-check"></i><b>6.3</b> Multiple linear regression models</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter7.html"><a href="chapter7.html"><i class="fa fa-check"></i><b>7</b> Wrap-up</a></li>
<li class="divider"></li>
<li>Developed by <a href="https://jumpingrivers.com" target="blank">Jumping Rivers</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Foundational Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter5" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Margin of Error</h1>
<blockquote>
<p>Testing leads to failure, and failure leads to understanding <em>Burt Rutan</em></p>
</blockquote>
<div id="introduction-motativating-example" class="section level2">
<h2><span class="header-section-number">5.1</span> Introduction &amp; motativating example</h2>
<p>Suppose we’re comparing two advert designs. At great expense, it has been decided to change the font to Comic Sans. Does this change work? Being a (data) scientist we decide to (humanely<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a>) experiment on people by randomly showing them the advert. From past experience, you know that customers spent 45 seconds (on average) on your site. After switching to comic sans, we recorded the amount of time spent on the site by 20 customers</p>
<pre><code>34 51 30 79 54 31 57 62 59 41 77 55 35  3 69 46 47 66 63 59</code></pre>
<p>Should we consider switching to comic sans?</p>
<p>Clearly time will vary visit–by–visit. On some visits, customers might spent more time (up to 79 seconds), but on others visits, they may only spend a few seconds. To get an overall impression, we could work out the average time for the above sample <span class="math display">\[
\bar x = \frac{34 + 51 + 30 + \ldots + 59}{20} = 50.9
\]</span> The new website does seem to be perform slightly better. But we have a very small sample. If we took another twenty visits, we would get a different estimate. We need to account for this sampling variability of the mean <span class="math inline">\(\bar x\)</span>, and the most common way of doing this is to perform a hypothesis test.</p>
</div>
<div id="one-sample-test" class="section level2">
<h2><span class="header-section-number">5.2</span> One sample test</h2>
<p>The one–sample z–test can be useful when we are interested in how the mean of a set of sample observations compares to some target value. The mean in our sample, as always, is denoted by <span class="math inline">\(\bar x\)</span>. The standard notation in statistics for the population mean is the Greek symbol <span class="math inline">\(\mu\)</span> (pronounced “mu”). Obviously, <span class="math inline">\(\bar x\)</span> is our sample estimate of <span class="math inline">\(\mu\)</span>.</p>
<p>In the example above, we’d like to know whether our new font has affected the amount of time people spend on our site. In hypothesis testing, we make this assertion in the null hypothesis, denoted by <span class="math inline">\(H_0\)</span> and often written down as <span class="math display">\[
H_0: \mu = 45
\]</span> We usually test against a general alternative hypothesis <span class="math inline">\(H_1\)</span> <span class="math display">\[
H_1: \mu \ne 45
\]</span> which says “<span class="math inline">\(\mu\)</span> is not equal to 45”.</p>
<p>When performing the hypothesis test, we <em>assume</em> <span class="math inline">\(H_0\)</span> to be true. We then ask ourselves the question:</p>
<blockquote>
<p>How likely is it that we would observe the data we have, or indeed anything more extreme than this, if the null hypothesis is true?</p>
</blockquote>
<p>We can get a handle on this question thanks to the Central Limit Theorem in Statistics. Although we will not go into the details here, this result tells us that the quantity <span class="math display">\[
Z = \frac{\bar x - \mu}{s/\sqrt{n}}
\]</span> follows a normal distribution (when <span class="math inline">\(n\)</span> is reasonably large). In this formula</p>
<ul>
<li><span class="math inline">\(\bar x\)</span> is our sample mean;</li>
<li><span class="math inline">\(\mu\)</span> is the assumed value of the population mean under the null hypothesis <span class="math inline">\(H_0\)</span>;</li>
<li><span class="math inline">\(s\)</span> is the sample standard deviation;</li>
<li><span class="math inline">\(n\)</span> is the sample size.</li>
</ul>
<div class="rmdnote">
<p>
When <span class="math inline"><em>n</em></span> is small, the central limit theorem tells us that <span class="math inline"><em>Z</em></span> follows a <span class="math inline"><em>t</em></span>-distribution. A <span class="math inline"><em>t</em></span> distribution is similar to the normal, except it has fatter tails (imagine pushing down on the normal distribution and spreading the weight). Provided your sample is large (<span class="math inline"><em>n</em> &gt; 10</span>), then the <span class="math inline"><em>z</em></span> and <span class="math inline"><em>t</em></span> tests are equivalent.
</p>
</div>
<p>Using our example data set, if the null hypothesis is true, then <span class="math inline">\(\mu = 45\)</span>, so we have <span class="math display">\[
Z = \frac{\bar x - \mu}{s/\sqrt{n}} = \frac{50.9 - 45}{18.2/\sqrt{20}} = 1.45
\]</span> The obvious question is, how likely is it to have observed this value?</p>
<p><img src="_main_files/figure-html/5-1-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>Since the normal distribution is symmetric, <span class="math inline">\(Z = 1.45\)</span> is just as extreme as <span class="math inline">\(Z = −1.45\)</span>, and so the shaded region in the following diagram illustrates the <span class="math inline">\(p\)</span>–value - the probability of observing the data we have, or anything more extreme than this, if the null hypothesis is true. In other words, the answer to our earlier question!</p>
<p>The closer the area of the shaded region (the <span class="math inline">\(p\)</span>–value) is to 0, the less plausible it is that we would observe the data we have if the null hypothesis is true, that is, the more evidence we have to reject <span class="math inline">\(H_0\)</span>. So, we need to work out the area of the shaded region under the curve in the diagram above, which can be done using R</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pnorm</span>(<span class="fl">1.45</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>) <span class="op">*</span><span class="st"> </span><span class="dv">2</span>
<span class="co">#&gt; [1] 0.147</span></code></pre></div>
<p>So the <span class="math inline">\(p\)</span>-value is 0.15.</p>
<p>Earlier, we said that the smaller this <span class="math inline">\(p\)</span>–value is, the more evidence we have to reject <span class="math inline">\(H_0\)</span>. The question now, is:</p>
<blockquote>
<p>What constitutes a p–value small enough to reject H_0?</p>
</blockquote>
<p>The convention (but by no means a hard–and–fast cut–off) is to reject <span class="math inline">\(H_0\)</span> if the p–value is smaller than 5%. Thus, here we would say:</p>
<ul>
<li>Our p–value is greater than 5% (in fact, it’s larger than 10% – a computer can tell us that it’s exactly 14.7%)</li>
<li>Thus, we do not reject <span class="math inline">\(H_0\)</span></li>
<li>There is insufficient evidence to suggest a real deviation from the previous value</li>
</ul>
<p>Care should be taken not be too strong in our conclusions. We can only really state that the sample does not suggest that the new design is better.</p>
<blockquote>
<p>Absence of evidence is not evidence of absence</p>
</blockquote>
<p>To perform the entire procedure in R, we use the <code>t.test()</code> function</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">comic =<span class="st"> </span><span class="kw">c</span>(<span class="dv">34</span>, <span class="dv">51</span>, <span class="dv">30</span>, <span class="dv">79</span>, <span class="dv">54</span>, <span class="dv">31</span>, <span class="dv">57</span>, <span class="dv">62</span>, <span class="dv">59</span>, <span class="dv">41</span>, <span class="dv">77</span>, <span class="dv">55</span>, <span class="dv">35</span>, <span class="dv">3</span>, <span class="dv">69</span>, <span class="dv">46</span>, <span class="dv">47</span>, <span class="dv">66</span>, <span class="dv">63</span>, <span class="dv">59</span>)
<span class="kw">t.test</span>(comic, <span class="dt">mu =</span> <span class="dv">45</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt;  One Sample t-test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  comic</span>
<span class="co">#&gt; t = 1, df = 20, p-value = 0.2</span>
<span class="co">#&gt; alternative hypothesis: true mean is not equal to 45</span>
<span class="co">#&gt; 95 percent confidence interval:</span>
<span class="co">#&gt;  42.4 59.4</span>
<span class="co">#&gt; sample estimates:</span>
<span class="co">#&gt; mean of x </span>
<span class="co">#&gt;      50.9</span></code></pre></div>
<p>Technically this is performing a t-test which is why the associated <span class="math inline">\(p\)</span>-value is slightly larger than our calculation. However, when the sample size is large, the <code>t.test()</code> function is equivalent to a z-test.</p>
<div id="example-okcupid-1" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Example: OKCupid</h3>
<p>The OKCupid dataset provides heights of their users. An interesting question is, how consistent are the heights given by users with the average height across the USA? First we need to extract the necessary information. R makes subsetting straightforward</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Select Males
height =<span class="st"> </span>cupid<span class="op">$</span>height[cupid<span class="op">$</span>sex <span class="op">==</span><span class="st"> &quot;m&quot;</span>]
## Remove missing values
height =<span class="st"> </span>height[<span class="op">!</span><span class="kw">is.na</span>(height)]
## Convert to cm
height =<span class="st"> </span>height <span class="op">*</span><span class="st"> </span><span class="fl">2.54</span>
<span class="kw">mean</span>(height)
<span class="co">#&gt; [1] 179</span></code></pre></div>
<p>From the <a href="https://www.cdc.gov/nchs/data/series/sr_11/sr11_252.pdf">CDC</a> paper we discover the average height in the USA is 69.3 inches. We can use the <span class="math inline">\(t\)</span>-test function in R (since the sample size is large, this is equivalent to a <span class="math inline">\(z\)</span>-test), to obtain a <span class="math inline">\(p\)</span>-value</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(height, <span class="dt">mu =</span> <span class="fl">69.3</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt;  One Sample t-test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  height</span>
<span class="co">#&gt; t = 3000, df = 40000, p-value &lt;2e-16</span>
<span class="co">#&gt; alternative hypothesis: true mean is not equal to 69.3</span>
<span class="co">#&gt; 95 percent confidence interval:</span>
<span class="co">#&gt;  179 179</span>
<span class="co">#&gt; sample estimates:</span>
<span class="co">#&gt; mean of x </span>
<span class="co">#&gt;       179</span></code></pre></div>
<p>Since the <span class="math inline">\(p\)</span>-value is small, we reject <span class="math inline">\(H_0\)</span> and conclude that the sample gives evidence that males in San Francisco are different to the rest of the USA (or just lie!).</p>
</div>
<div id="errors" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Errors</h3>
<p>A Type I Error occurs when the null hypothesis is true but is wrongly rejected. This often referred to as a “false hit”“, or a false positive (e.g. when a diagnostic test indicates the presence of a disease, when in fact the patient does not have the disease).</p>
<p>The rate of a Type I Error is known as the size of the test and is usually denoted by the Greek symbol <span class="math inline">\(\alpha\)</span>, pronounced “alpha”, and usually equals the significance level of the test - that is, the p–value beyond which we have decided to reject H 0 (e.g. 5% or 0.05 in our earlier examples).</p>
<p>A Type II Error occurs when the null hypothesis is false, but erroneously fails to be rejected. Hence, we fail to assert what is present, and so this is often referred to as a ‘miss’. The rate of the Type II Error is usually denoted by the Greek symbol <span class="math inline">\(\beta\)</span>, pronounced “beta”, and is related to the power of a test (which equals 1 − <span class="math inline">\(\beta\)</span>).</p>
<div class="figure">
<img src="graphics/type1and2.jpg" />

</div>
</div>
</div>
<div id="two-sample-z-test" class="section level2">
<h2><span class="header-section-number">5.3</span> Two sample z-test</h2>
<p>Suppose we want to test another improvement to our website. We think that adding a <a href="https://en.wikipedia.org/wiki/Blink_element">blink</a> tag would be a good way of attracting customers. Monitoring the first twenty customers we get</p>
<pre><code>21 32 46 19 29 31 37 28 50 29 34 40 26 20 48  7 39 30 40 34</code></pre>
<p>How do we compare the website that uses the Comic Sans font to the blinking site? We use a two sampled z-test! As with the one–sample test, we must start by setting up our hypotheses. In a two–sample z test, the null hypothesis is always that the population means for the two groups are the same <span class="math display">\[
H_0: \mu_1 = \mu_2
\]</span> While the alternative hypothesis is that the two pages differ, i.e. <span class="math display">\[
H_1: \mu_1 \ne  \mu_2.
\]</span> The corresponding test statistic is <span class="math display">\[
Z = \frac{\bar x_1 - \bar x_2}{s \sqrt{1/n_1 + 1/n_2}}.
\]</span> This time we will jump straight into R and use the <code>t.test()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">blink =<span class="st"> </span><span class="kw">c</span>(<span class="dv">21</span>, <span class="dv">32</span>, <span class="dv">46</span>, <span class="dv">19</span>, <span class="dv">29</span>, <span class="dv">31</span>, <span class="dv">37</span>, <span class="dv">28</span>, <span class="dv">50</span>, <span class="dv">29</span>, <span class="dv">34</span>, <span class="dv">40</span>, <span class="dv">26</span>, <span class="dv">20</span>, <span class="dv">48</span>, <span class="dv">7</span>, <span class="dv">39</span>, <span class="dv">30</span>, <span class="dv">40</span>, <span class="dv">34</span>)
<span class="kw">t.test</span>(comic, blink, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt;  Two Sample t-test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  comic and blink</span>
<span class="co">#&gt; t = 4, df = 40, p-value = 3e-04</span>
<span class="co">#&gt; alternative hypothesis: true difference in means is not equal to 0</span>
<span class="co">#&gt; 95 percent confidence interval:</span>
<span class="co">#&gt;   9.37 28.43</span>
<span class="co">#&gt; sample estimates:</span>
<span class="co">#&gt; mean of x mean of y </span>
<span class="co">#&gt;      50.9      32.0</span></code></pre></div>
<p>In this example, since the p-value is relatively, we can conclude that the two web-designs do appear to be different.</p>
</div>
<div id="confidence-intervals" class="section level2">
<h2><span class="header-section-number">5.4</span> Confidence intervals</h2>
<p>The idea of a confidence interval is central to statistics. When we get an answer, we don’t just want a point estimate, i.e. a single number, we want a plausible range. In fact whenever you see opinion polls in newspapers, they typically come with a margin of error of <span class="math inline">\(\pm 3\)</span>%. It’s always amusing to see the fuss that people make when an opinion poll raises by 1% which is likely to be down to random noise.</p>
<p>Confidence intervals provide an alternative to hypothesis tests for assessing questions about the population mean (or population means in two sample problems), although often they are used alongside hypothesis tests. Due to lack of time, we will not cover the general theory supporting the construction of confidence intervals, although this theory is the same as that discussed in Section 4 for hypothesis tests and revolves around the Central Limit Theorem. The aim is to use the information in our sample to obtain an interval within which we might expect the true population mean to lie, with a specified level of confidence.</p>
<p>Recall that the sample mean <span class="math inline">\(\bar x\)</span> is an estimate of the population mean <span class="math inline">\(\mu\)</span>. The population mean does exist; we’d like to know what it is, but usually this isn’t possible (unless we are able to take a census). The next best thing is to take a sample from the population and find <span class="math inline">\(\bar x\)</span> - if our sample is representative of the population as a whole, we might feel confident that <span class="math inline">\(\bar x\)</span> is a good estimator for <span class="math inline">\(\mu\)</span>, and might be close to the true value.</p>
<p>The problem is, if we were to take many samples from the population, and so calculate many <span class="math inline">\(\bar x\)</span>’s, they are all likely to be different to each other. Which one would we trust the most? In reality, we don’t have the resources to take many samples, and so we’d like a way of capturing the variability of $x $ based on the information in our single sample. This is where statistical theory can help us out!</p>
<p>Central to the idea of margin of error, is the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem"><em>central limit theorem</em></a>.</p>
<div id="construction" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Construction</h3>
<p>Most confidence intervals are symmetric and two–sided. Thus, to obtain a confidence interval for the population mean we:</p>
<ol style="list-style-type: decimal">
<li>Find the mean in our sample, <span class="math inline">\(\bar x\)</span></li>
<li>Subtract some amount from <span class="math inline">\(\bar x\)</span> to obtain the <em>lower bound</em> of our confidence interval</li>
<li>Add the same amount in (2) to our sample mean <span class="math inline">\(\bar x\)</span> to obtain the <em>upper bound</em> of our confidence interval</li>
</ol>
<p>The amount we add and subtract from <span class="math inline">\(\bar x\)</span> is a function of the sample standard deviation <span class="math inline">\(s\)</span> and the sample size <span class="math inline">\(n\)</span>; it also depends on just how “confident”&quot; we want to be of capturing the population mean <span class="math inline">\(\mu\)</span> within our interval! To be 100% confident, the lower and upper bounds would need to extend to the smallest and largest values possible for our random variable, and so it makes no sense to find such an interval; the standard is to find a <em>95% confidence interval</em>.</p>
<p>The formula for a symmetric, two–sided 95% confidence interval for the population mean <span class="math inline">\(\mu\)</span> is <span class="math display">\[
\left(\bar{x}-z \times \frac{s}{\sqrt{n}}, \hspace{0.5cm} \bar{x}+z\times \frac{s}{\sqrt{n}}\right),
\]</span> often condensed to just <span class="math display">\[
\bar{x} \pm z \times \frac{s}{\sqrt{n}};
\]</span> where <span class="math inline">\(z\)</span> is a critical value from the standard normal distribution. For the standard interval 95% confidence interval, the <span class="math inline">\(z\)</span> value is 1.96, often rounded to 2. So the interval becomes <span class="math display">\[
\bar{x} \pm \frac{2 s}{\sqrt{n}}.
\]</span> If we wanted a 90% interval, we would use <span class="math inline">\(z = 1.645\)</span>. For a 99% interval, we would use <span class="math inline">\(z = 2.576\)</span></p>
</div>
<div id="example-comic-sans" class="section level3">
<h3><span class="header-section-number">5.4.2</span> Example: Comic Sans</h3>
<p>Let’s return to our Comics Sans example. The average time spent on the site was <span class="math inline">\(\bar x = 50.9\)</span> with a standard deviation of <span class="math inline">\(s = 18.2\)</span>. This gives a 95% confidence interval of <span class="math display">\[
50.9 \pm 1.96 \frac{18.2}{\sqrt{20}} = (42.92, 58.88).
\]</span> Alternatively, we could use R and extract the confidence interval from</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(comic)
<span class="co">#&gt; </span>
<span class="co">#&gt;  One Sample t-test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  comic</span>
<span class="co">#&gt; t = 10, df = 20, p-value = 1e-10</span>
<span class="co">#&gt; alternative hypothesis: true mean is not equal to 0</span>
<span class="co">#&gt; 95 percent confidence interval:</span>
<span class="co">#&gt;  42.4 59.4</span>
<span class="co">#&gt; sample estimates:</span>
<span class="co">#&gt; mean of x </span>
<span class="co">#&gt;      50.9</span></code></pre></div>
<p>to get the interval <span class="math inline">\((42.38,59.42)\)</span>. Notice this interval is slightly wider, since it’s using the exact <span class="math inline">\(t\)</span>-distribution.</p>
</div>
</div>
<div id="the-central-limit-therem-clt" class="section level2">
<h2><span class="header-section-number">5.5</span> The Central Limit Therem (CLT)</h2>
<!-- XXX That have finite mean and variance -->
<p>One of the reasons the normal distribution is so useful is the central limit theorem. This theorem states that if we average a large number (say 30<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a>) of variables<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a>, then the result is approximately normally distributed.</p>
<p>So if we observe data, <span class="math inline">\(x_1, x_2, \ldots, x_n\)</span>, where the mean and variance of <span class="math inline">\(x_i\)</span> are <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>, then <span class="math display">\[
S_n = \frac{x_1 + x_2 + \ldots + x_n}{n}
\]</span> has a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2/n\)</span>.</p>
<p>The standard error of the mean is defined as the standard deviation of the sample mean, i.e. <span class="math inline">\(\sigma/\sqrt{n}\)</span>. Remember that <span class="math inline">\(\sigma\)</span> is the population standard deviation, so we <em>estimate</em> the standard error using <span class="math inline">\(s/\sqrt{n}\)</span></p>
<!-- XXX think this note reads funny, but struggling to think of what I would put -->
<div id="example-customer-waiting-times" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Example: Customer waiting times</h3>
<div class="figure" style="text-align: center"><span id="fig:5-2"></span>
<img src="_main_files/figure-html/5-2-1.png" alt="Waiting times from 40 customers. The data is skewed and is not normally distributed." width="60%" />
<p class="caption">
Figure 5.1: Waiting times from 40 customers. The data is skewed and is not normally distributed.
</p>
</div>
<!-- XXX might be easier to see if you had a histogram next to it? -->
<p>Figure <a href="chapter5.html#fig:5-2">5.1</a> shows the waiting time (in minutes) of <span class="math inline">\(40\)</span> customers. The figure shows that the average wait is around 1 to 2 minutes, but some unfortunate customers have a significantly longer wait. The data are clearly not normal, as waiting times must be positive and the distribution isn’t symmetric.</p>
<p>From chapter 2, we can quickly estimate the mean and standard deviation as 1.946 and 0.433, i.e. <span class="math inline">\(S_n = 1.946\)</span> . The CLT allows us to take this inference one step further. Since we know that <span class="math inline">\(S_n\)</span> is approximately normal, that implies that with probability 95%, the true mean lies between <span class="math inline">\(2.19 \pm 2 \times 2.04/20 = (1.28, 3.1).\)</span></p>
<div class="rmdwarning">
<p>
Mathematically the central limit theorem only holds as <span class="math inline"><em>n</em></span> tends to infinity. However in this simple example, the underlying distribution is clearly not normal, so the confidence interval, given our finite sample, isn’t actually 95%, it’s more like 91%. Which is still not too bad.
</p>
</div>
<p>The central limit theorem is a powerful idea. It allows to get a handle on the uncertainty whenever we estimate means. One word of warning though. If the distribution is particularly odd, then we’ll need a larger sample size for the normality approximation to be accurate.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="8">
<li id="fn8"><p>Is using Comic Sans humane? Discuss.<a href="chapter5.html#fnref8">↩</a></p></li>
<li id="fn9"><p>Puts big data into perspective!<a href="chapter5.html#fnref9">↩</a></p></li>
<li id="fn10"><p>The key phrase is independent and identically distributed random variables.<a href="chapter5.html#fnref10">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter4.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter6.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-margin-of-error.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
