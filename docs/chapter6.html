<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Foundational Data Science</title>
  <meta name="description" content="This course provides a firm foundation on the fundamentals of data science using R, with a focus on key statistical methods, exploratory data analysis, and visualizations. Before worrying about advanced analytics and neural nets, it is important to master the core skills. While this is certainly not a mathematical course, we won’t shy away from giving insight into the underlying mathematical theory.">
  <meta name="generator" content="bookdown 0.6 and GitBook 2.6.7">

  <meta property="og:title" content="Foundational Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://csgillespie.github.io/foundational-data-science/" />
  
  <meta property="og:description" content="This course provides a firm foundation on the fundamentals of data science using R, with a focus on key statistical methods, exploratory data analysis, and visualizations. Before worrying about advanced analytics and neural nets, it is important to master the core skills. While this is certainly not a mathematical course, we won’t shy away from giving insight into the underlying mathematical theory." />
  <meta name="github-repo" content="csgillespie/foundational-data-science" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Foundational Data Science" />
  <meta name="twitter:site" content="@csgillespie" />
  <meta name="twitter:description" content="This course provides a firm foundation on the fundamentals of data science using R, with a focus on key statistical methods, exploratory data analysis, and visualizations. Before worrying about advanced analytics and neural nets, it is important to master the core skills. While this is certainly not a mathematical course, we won’t shy away from giving insight into the underlying mathematical theory." />
  

<meta name="author" content="Colin Gillespie">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chapter5.html">
<link rel="next" href="chapter7.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Foundational Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Author</a></li>
<li class="chapter" data-level="1" data-path="chapter1.html"><a href="chapter1.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="chapter1.html"><a href="chapter1.html#book-overview"><i class="fa fa-check"></i><b>1.1</b> Book overview</a><ul>
<li class="chapter" data-level="1.1.1" data-path="chapter1.html"><a href="chapter1.html#the-trouble-with-tibbles-data"><i class="fa fa-check"></i><b>1.1.1</b> The trouble with <del>tibbles</del> data</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="chapter1.html"><a href="chapter1.html#talking-about-data"><i class="fa fa-check"></i><b>1.2</b> Talking about data</a><ul>
<li class="chapter" data-level="1.2.1" data-path="chapter1.html"><a href="chapter1.html#sample-size"><i class="fa fa-check"></i><b>1.2.1</b> Sample size</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="chapter1.html"><a href="chapter1.html#designing-the-experiment"><i class="fa fa-check"></i><b>1.3</b> Designing the experiment</a></li>
<li class="chapter" data-level="1.4" data-path="chapter1.html"><a href="chapter1.html#data-sets"><i class="fa fa-check"></i><b>1.4</b> Data sets</a><ul>
<li class="chapter" data-level="1.4.1" data-path="chapter1.html"><a href="chapter1.html#the-relationship-between-beauty-and-teaching"><i class="fa fa-check"></i><b>1.4.1</b> The relationship between beauty and teaching</a></li>
<li class="chapter" data-level="1.4.2" data-path="chapter1.html"><a href="chapter1.html#bond-james-bond"><i class="fa fa-check"></i><b>1.4.2</b> Bond, James Bond</a></li>
<li class="chapter" data-level="1.4.3" data-path="chapter1.html"><a href="chapter1.html#okcupid"><i class="fa fa-check"></i><b>1.4.3</b> OKCupid</a></li>
<li class="chapter" data-level="1.4.4" data-path="chapter1.html"><a href="chapter1.html#starbucks"><i class="fa fa-check"></i><b>1.4.4</b> Starbucks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> Condensing data with numerical summaries</a><ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#mathematical-notation"><i class="fa fa-check"></i><b>2.1</b> Mathematical notation</a></li>
<li class="chapter" data-level="2.2" data-path="chapter2.html"><a href="chapter2.html#measures-of-location"><i class="fa fa-check"></i><b>2.2</b> Measures of location</a><ul>
<li class="chapter" data-level="2.2.1" data-path="chapter2.html"><a href="chapter2.html#sample-mean"><i class="fa fa-check"></i><b>2.2.1</b> Sample mean</a></li>
<li class="chapter" data-level="" data-path="chapter2.html"><a href="chapter2.html#example-the-beauty-data-set"><i class="fa fa-check"></i>Example: The beauty data set</a></li>
<li class="chapter" data-level="2.2.2" data-path="chapter2.html"><a href="chapter2.html#sample-median"><i class="fa fa-check"></i><b>2.2.2</b> Sample median</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="chapter2.html"><a href="chapter2.html#measures-of-spread"><i class="fa fa-check"></i><b>2.3</b> Measures of spread</a><ul>
<li class="chapter" data-level="2.3.1" data-path="chapter2.html"><a href="chapter2.html#range"><i class="fa fa-check"></i><b>2.3.1</b> Range</a></li>
<li class="chapter" data-level="2.3.2" data-path="chapter2.html"><a href="chapter2.html#sample-variance-and-standard-deviation"><i class="fa fa-check"></i><b>2.3.2</b> Sample variance and standard deviation</a></li>
<li class="chapter" data-level="2.3.3" data-path="chapter2.html"><a href="chapter2.html#quartiles-and-the-interquartile-range"><i class="fa fa-check"></i><b>2.3.3</b> Quartiles and the interquartile range</a></li>
<li class="chapter" data-level="2.3.4" data-path="chapter2.html"><a href="chapter2.html#numerical-examples"><i class="fa fa-check"></i><b>2.3.4</b> Numerical examples</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="chapter2.html"><a href="chapter2.html#streaming-data"><i class="fa fa-check"></i><b>2.4</b> Streaming data</a><ul>
<li class="chapter" data-level="2.4.1" data-path="chapter2.html"><a href="chapter2.html#the-mean-and-variance"><i class="fa fa-check"></i><b>2.4.1</b> The mean and variance</a></li>
<li class="chapter" data-level="2.4.2" data-path="chapter2.html"><a href="chapter2.html#the-median-and-quantiles"><i class="fa fa-check"></i><b>2.4.2</b> The median and quantiles</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="chapter2.html"><a href="chapter2.html#relevant-r-functions"><i class="fa fa-check"></i>Relevant R functions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> What, why and how of visualisation</a><ul>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#historical-visualisations"><i class="fa fa-check"></i><b>3.1</b> Historical visualisations</a></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#scatter-plots"><i class="fa fa-check"></i><b>3.2</b> Scatter plots</a><ul>
<li class="chapter" data-level="3.2.1" data-path="chapter3.html"><a href="chapter3.html#styling-your-plot"><i class="fa fa-check"></i><b>3.2.1</b> Styling your plot</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="chapter3.html"><a href="chapter3.html#histograms"><i class="fa fa-check"></i><b>3.3</b> Histograms</a></li>
<li class="chapter" data-level="3.4" data-path="chapter3.html"><a href="chapter3.html#density-plots"><i class="fa fa-check"></i><b>3.4</b> Density plots</a><ul>
<li class="chapter" data-level="3.4.1" data-path="chapter3.html"><a href="chapter3.html#detailed-explanation"><i class="fa fa-check"></i><b>3.4.1</b> Detailed explanation</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="chapter3.html"><a href="chapter3.html#boxplots"><i class="fa fa-check"></i><b>3.5</b> Boxplots</a></li>
<li class="chapter" data-level="3.6" data-path="chapter3.html"><a href="chapter3.html#barplots"><i class="fa fa-check"></i><b>3.6</b> Barplots</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter4.html"><a href="chapter4.html"><i class="fa fa-check"></i><b>4</b> The normal distribution - what’s the point?</a><ul>
<li class="chapter" data-level="4.1" data-path="chapter4.html"><a href="chapter4.html#the-bernoulli-distribution"><i class="fa fa-check"></i><b>4.1</b> The Bernoulli distribution</a><ul>
<li class="chapter" data-level="4.1.1" data-path="chapter4.html"><a href="chapter4.html#motivating-example"><i class="fa fa-check"></i><b>4.1.1</b> Motivating example</a></li>
<li class="chapter" data-level="4.1.2" data-path="chapter4.html"><a href="chapter4.html#description"><i class="fa fa-check"></i><b>4.1.2</b> Description</a></li>
<li class="chapter" data-level="4.1.3" data-path="chapter4.html"><a href="chapter4.html#example"><i class="fa fa-check"></i><b>4.1.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="chapter4.html"><a href="chapter4.html#the-binomial-distribution"><i class="fa fa-check"></i><b>4.2</b> The Binomial distribution</a><ul>
<li class="chapter" data-level="4.2.1" data-path="chapter4.html"><a href="chapter4.html#motivating-example-1"><i class="fa fa-check"></i><b>4.2.1</b> Motivating example</a></li>
<li class="chapter" data-level="4.2.2" data-path="chapter4.html"><a href="chapter4.html#description-1"><i class="fa fa-check"></i><b>4.2.2</b> Description</a></li>
<li class="chapter" data-level="4.2.3" data-path="chapter4.html"><a href="chapter4.html#what-does-the-binomial-distribution-look-like"><i class="fa fa-check"></i><b>4.2.3</b> What does the Binomial distribution look like?</a></li>
<li class="chapter" data-level="4.2.4" data-path="chapter4.html"><a href="chapter4.html#motivating-example-2"><i class="fa fa-check"></i><b>4.2.4</b> Motivating example</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="chapter4.html"><a href="chapter4.html#the-normalgaussian-distribution"><i class="fa fa-check"></i><b>4.3</b> The Normal/Gaussian distribution</a><ul>
<li class="chapter" data-level="4.3.1" data-path="chapter4.html"><a href="chapter4.html#continuous-and-discrete-distributions"><i class="fa fa-check"></i><b>4.3.1</b> Continuous and discrete distributions</a></li>
<li class="chapter" data-level="4.3.2" data-path="chapter4.html"><a href="chapter4.html#the-standard-deviations-rule"><i class="fa fa-check"></i><b>4.3.2</b> The standard deviations rule</a></li>
<li class="chapter" data-level="4.3.3" data-path="chapter4.html"><a href="chapter4.html#the-z-score"><i class="fa fa-check"></i><b>4.3.3</b> The Z-Score</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter5.html"><a href="chapter5.html"><i class="fa fa-check"></i><b>5</b> Margin of Error</a><ul>
<li class="chapter" data-level="5.1" data-path="chapter5.html"><a href="chapter5.html#introduction-motativating-example"><i class="fa fa-check"></i><b>5.1</b> Introduction &amp; motativating example</a></li>
<li class="chapter" data-level="5.2" data-path="chapter5.html"><a href="chapter5.html#one-sample-test"><i class="fa fa-check"></i><b>5.2</b> One sample test</a><ul>
<li class="chapter" data-level="5.2.1" data-path="chapter5.html"><a href="chapter5.html#example-okcupid-1"><i class="fa fa-check"></i><b>5.2.1</b> Example: OKCupid</a></li>
<li class="chapter" data-level="5.2.2" data-path="chapter5.html"><a href="chapter5.html#errors"><i class="fa fa-check"></i><b>5.2.2</b> Errors</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="chapter5.html"><a href="chapter5.html#two-sample-z-test"><i class="fa fa-check"></i><b>5.3</b> Two sample z-test</a></li>
<li class="chapter" data-level="5.4" data-path="chapter5.html"><a href="chapter5.html#confidence-intervals"><i class="fa fa-check"></i><b>5.4</b> Confidence intervals</a><ul>
<li class="chapter" data-level="5.4.1" data-path="chapter5.html"><a href="chapter5.html#construction"><i class="fa fa-check"></i><b>5.4.1</b> Construction</a></li>
<li class="chapter" data-level="5.4.2" data-path="chapter5.html"><a href="chapter5.html#example-comic-sans"><i class="fa fa-check"></i><b>5.4.2</b> Example: Comic Sans</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="chapter5.html"><a href="chapter5.html#the-central-limit-therem-clt"><i class="fa fa-check"></i><b>5.5</b> The Central Limit Therem (CLT)</a><ul>
<li class="chapter" data-level="5.5.1" data-path="chapter5.html"><a href="chapter5.html#example-customer-waiting-times"><i class="fa fa-check"></i><b>5.5.1</b> Example: Customer waiting times</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter6.html"><a href="chapter6.html"><i class="fa fa-check"></i><b>6</b> Capturing relationships with linear regression</a><ul>
<li class="chapter" data-level="6.1" data-path="chapter6.html"><a href="chapter6.html#capturing-linear-relationships"><i class="fa fa-check"></i><b>6.1</b> Capturing linear relationships</a><ul>
<li class="chapter" data-level="6.1.1" data-path="chapter6.html"><a href="chapter6.html#example-starbucks-calorie-content"><i class="fa fa-check"></i><b>6.1.1</b> Example: Starbucks calorie content</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="chapter6.html"><a href="chapter6.html#linear-regression"><i class="fa fa-check"></i><b>6.2</b> Linear Regression</a><ul>
<li class="chapter" data-level="6.2.1" data-path="chapter6.html"><a href="chapter6.html#prediction-and-interpretation"><i class="fa fa-check"></i><b>6.2.1</b> Prediction and Interpretation</a></li>
<li class="chapter" data-level="6.2.2" data-path="chapter6.html"><a href="chapter6.html#how-do-we-estimate-the-model-coefficients"><i class="fa fa-check"></i><b>6.2.2</b> How do we estimate the model coefficients?</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="chapter6.html"><a href="chapter6.html#multiple-linear-regression-models"><i class="fa fa-check"></i><b>6.3</b> Multiple linear regression models</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter7.html"><a href="chapter7.html"><i class="fa fa-check"></i><b>7</b> Wrap-up</a></li>
<li class="divider"></li>
<li>Developed by <a href="https://jumpingrivers.com" target="blank">Jumping Rivers</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Foundational Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter6" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Capturing relationships with linear regression</h1>
<!-- (90 minutes) -->
<p>In many data science problems, we wish to use information about some variables to help predict the outcome of another variable. For example, in banking, we might wish to use a persons financial history to predict the likelihood of them defaulting on a mortgage. The idea of using past data to predict future events is central to data science and statistics.</p>
<p>The simplest relationship between two variables is linear. The correlation coefficient will provide a single number summary of this relationship. To use the linear interaction for prediction, we need to use linear regression techniques. In our final chapter, we will look at standard modelling techniques.<br />
We’ll start with the simplest measure, correlation, before moving onto linear regression models.</p>
<div id="capturing-linear-relationships" class="section level2">
<h2><span class="header-section-number">6.1</span> Capturing linear relationships</h2>
<p>The easiest way to quantify the relationship between two variables is to calculate the correlation coefficient. This is a measure of the <em>linear</em> association. The sample correlation coefficient is defined as <span class="math display">\[
r=\frac {\sum _{i=1}^{n}(x_{i}-{\bar {x}})(y_{i}-{\bar {y}})}{{\sqrt {\sum _{i=1}^{n}(x_{i}-{\bar {x}})^{2}}}{\sqrt {\sum _{i=1}^{n}(y_{i}-{\bar {y}})^{2}}}}
\]</span> where</p>
<ul>
<li><span class="math inline">\(n\)</span> is the sample size;.</li>
<li><span class="math inline">\(x_{i},y_{i}\)</span> are the single samples indexed with <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(\bar {x} = \frac {1}{n} \sum _{i=1}^{n} x_{i}\)</span> is the (the sample mean).</li>
</ul>
<p>The value of <span class="math inline">\(r\)</span> lies between <span class="math inline">\(-1\)</span> and <span class="math inline">\(1\)</span>. A value of <span class="math inline">\(1\)</span> implies that all data points lie on a line as <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> increase. A values of <span class="math inline">\(-1\)</span> implies that all data points lie on a line where <span class="math inline">\(Y\)</span> decreases as <span class="math inline">\(X\)</span> increases. A value of 0 implies that there is no linear correlation between the variables.</p>

<div class="figure" style="text-align: center"><span id="fig:6-1"></span>
<img src="_main_files/figure-html/6-1-1.png" alt="Several sets of (x, y) points, with the correlation coefficient of x and y for each set. Credit: Wikipedia" width="60%" />
<p class="caption">
Figure 6.1: Several sets of (x, y) points, with the correlation coefficient of x and y for each set. Credit: <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence">Wikipedia</a>
</p>
</div>
<p>Figure <a href="chapter6.html#fig:6-1">6.1</a> (shamelessly stolen from wikipedia) gives a very useful overview of the correlation coefficient. The top row of plot shows how data changes as we move from a coefficient of <span class="math inline">\(+1\)</span> to <span class="math inline">\(-1\)</span>. When <span class="math inline">\(r = 0\)</span>, we just have random scatter.</p>
<p>Something that is often forgotten, is that correlation <em>does not</em> measure the strength of the linear association. This is clear from the second row of figure <a href="chapter6.html#fig:6-1">6.1</a> where it is clear that the correlation does not depend on the gradient.</p>
<p>The final row of figure <a href="chapter6.html#fig:6-1">6.1</a> shows figures where the correlation cofficient is 0. However, in each example there is clearly a relationship; it’s just not linear.</p>
<div class="rmdnote">
<p>
Calculating the correlation is a useful first step when you first come across a data set. My typical first step is to run <code>image(cor(data_set))</code>. This produces a very ugly, but informative heatmap of the correlation cofficients.
</p>
</div>
<div id="example-starbucks-calorie-content" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Example: Starbucks calorie content</h3>
<p>The Starbucks data set contains nutritional value of 113 items. For each item on the menu we have the number of calories, and the carbohydrate, fat, fiber and protein amount.</p>
<p>We can quickly get an overview in R,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(starbucks)
<span class="co">#&gt;                                  Product Calories Fat Carb Fiber Protein</span>
<span class="co">#&gt; 1                           Chonga Bagel      300   5   50     3      12</span>
<span class="co">#&gt; 2                           8-Grain Roll      380   6   70     7      10</span>
<span class="co">#&gt; 3                       Almond Croissant      410  22   45     3      10</span>
<span class="co">#&gt; 4                          Apple Fritter      460  23   56     2       7</span>
<span class="co">#&gt; 5                       Banana Nut Bread      420  22   52     2       6</span>
<span class="co">#&gt; 6 Blueberry Muffin with Yogurt and Honey      380  16   53     1       6</span></code></pre></div>
and generate a few scatter plots <a href="chapter6.html#fig:6-2">6.2</a>.
<div class="figure" style="text-align: center"><span id="fig:6-2"></span>
<img src="_main_files/figure-html/6-2-1.png" alt="Relationships of Calories content and ingredients." width="90%" />
<p class="caption">
Figure 6.2: Relationships of Calories content and ingredients.
</p>
</div>
<p>The scatter plots show a clear linear trend. To work out the sample pairwise correlations we use the <code>cor()</code> function</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Drop the first column since it&#39;s the food names
<span class="kw">cor</span>(starbucks[, <span class="op">-</span><span class="dv">1</span>])
<span class="co">#&gt;          Calories   Fat  Carb Fiber Protein</span>
<span class="co">#&gt; Calories    1.000 0.829 0.708 0.471   0.619</span>
<span class="co">#&gt; Fat         0.829 1.000 0.281 0.276   0.423</span>
<span class="co">#&gt; Carb        0.708 0.281 1.000 0.408   0.204</span>
<span class="co">#&gt; Fiber       0.471 0.276 0.408 1.000   0.472</span>
<span class="co">#&gt; Protein     0.619 0.423 0.204 0.472   1.000</span></code></pre></div>
<p>The R output returns all pairwise correlations between the 5 variables:</p>
<ul>
<li>There is a diagonal of 1, since the correlation of a variable with itself is 1.</li>
<li>The matrix is <em>symmetric</em> since the correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is the same as the correlation between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>.</li>
</ul>
<p>Out of the four component parts, <code>Fat</code> is very highly correlated with <code>Calories</code>.</p>
</div>
</div>
<div id="linear-regression" class="section level2">
<h2><span class="header-section-number">6.2</span> Linear Regression</h2>
<p>The next step is use information about one variable to inform you about another. If you recall back to your school days, you’ll hopefully remember that the equation of a straight line is <span class="math display">\[
Y = \beta_0 + \beta_1 x
\]</span> where</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span> is the <span class="math inline">\(y\)</span>-intercept (in the UK, we used <span class="math inline">\(c\)</span> instead of <span class="math inline">\(\beta_0\)</span>);</li>
<li><span class="math inline">\(\beta_1\)</span> is the gradient (in the UK, we used <span class="math inline">\(m\)</span> instead of <span class="math inline">\(\beta_1\)</span>).</li>
</ul>
<p>In statistics, we usually call <span class="math inline">\(Y\)</span> the response variable (the thing we want to predict) and <span class="math inline">\(x\)</span> the predictor (or covariate). The aim of the model is to estimate the values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. However, since we only have a sample, there is uncertainity surrounding our estimate.</p>
<p>To fit the model in R, we use the <code>lm()</code><a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a> function</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># This is an R formula</span>
<span class="co"># Read as: Calories is modeled by Fat</span>
(<span class="dt">m =</span> <span class="kw">lm</span>(Calories <span class="op">~</span><span class="st"> </span>Fat, <span class="dt">data =</span> starbucks))
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = Calories ~ Fat, data = starbucks)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt; (Intercept)          Fat  </span>
<span class="co">#&gt;       148.0         12.8</span></code></pre></div>
<p>The output from R gives estimates of <span class="math inline">\(\beta_0 = 148.0\)</span> and <span class="math inline">\(\beta_1 = 12.8\)</span>.</p>
<div id="prediction-and-interpretation" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Prediction and Interpretation</h3>
<p>The estimated model, <span class="math display">\[
\text{Calories} = 148 + 12.8 \times \text{Fat}
\]</span> allows us to predict the calorie content based on the fat. For example, if the fat content was 10, then the estimated calorie content would be 276. However this simple example also highlights the potential dangers of using the model for prediction. If we wished to predict the calorie content of fat-free food, i.e. <span class="math inline">\(\text{Fat} = 0\)</span>, then our model would estimate the calorie content as <span class="math inline">\(148\)</span>. This seems a bit high for a glass of water! The obvious reason for this poor fit is that our model isn’t capturing our aspects of the relationship or is missing other significant covariates.</p>
</div>
<div id="how-do-we-estimate-the-model-coefficients" class="section level3">
<h3><span class="header-section-number">6.2.2</span> How do we estimate the model coefficients?</h3>
<p>We estimate the model parameters by “minimising the sum of squared residuals”. A residual is the difference between the observed value and the predicted value. In figure <a href="chapter6.html#fig:6-3">6.3</a>, the observed values, i.e. the data, are the black dots and the residuals are the solid lines. The line of best fit is the dashed line. In figure <a href="chapter6.html#fig:6-3">6.3</a> we have five data points, so we must have five residuals.</p>
<p>The classical <em>statistics interpretation</em> of a linear regression model is to assume the underlying model is actually <span class="math display">\[
Y = \beta_0 + \beta_1 x + \epsilon
\]</span> where <span class="math inline">\(\epsilon\)</span> is normally distributed. If assume that the errors (<span class="math inline">\(\epsilon\)</span>) follow a normal distribution, then to estimate the parameter values we minimise the sum of squared residuals.</p>
<div class="figure" style="text-align: center"><span id="fig:6-3"></span>
<img src="_main_files/figure-html/6-3-1.png" alt="Residuals and linear regression." width="60%" />
<p class="caption">
Figure 6.3: Residuals and linear regression.
</p>
</div>
<p>The <em>machine learning</em> interpretation is that we have a cost function that we wish to minimise. It just so happens that in this particular case, that the cost function corresponds to assuming normality. But we could have used any cost function. To assess model fit, we would typically use <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">Cross validation</a> or a similar method.</p>
<p>One approach isn’t better than the other. The statistics approach gives more insight into the mechanisms, but the <em>machine learning</em> approach leads to a better predictive model. As in most cases, a combination of both methods is the optimal approach.</p>
</div>
</div>
<div id="multiple-linear-regression-models" class="section level2">
<h2><span class="header-section-number">6.3</span> Multiple linear regression models</h2>
<p>A multiple linear regression model is the natural extension of the simple linear regression model. If we have two predictors, e.g. <span class="math display">\[
Y = \beta_0 + \beta_1 \text{Fat} + \beta_2 \text{Carb}
\]</span> This is equivalent to fitting a plane (a sheet of paper) through the points (figure <a href="chapter6.html#fig:6-4">6.4</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:6-4"></span>
<img src="_main_files/figure-html/6-4-1.png" alt="Illustration of multiple linear regression with two predictor variables." width="95%" />
<p class="caption">
Figure 6.4: Illustration of multiple linear regression with two predictor variables.
</p>
</div>
<p>When we have more than two predictor variables, the geometric interpretation gets messy, but it’s still the same idea.</p>
<p>The parameter estimating procedure is identical to simple linear regression - we wish to minimise the sum of squared residuals. Furthermore, we still have the two views of the model: the statistical and machine learning.</p>
<p>Fitting the model in R is a simple extension</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(<span class="dt">m =</span> <span class="kw">lm</span>(Calories <span class="op">~</span><span class="st"> </span>Fat <span class="op">+</span><span class="st"> </span>Carb, <span class="dt">data =</span> starbucks))
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = Calories ~ Fat + Carb, data = starbucks)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt; (Intercept)          Fat         Carb  </span>
<span class="co">#&gt;       11.36        10.52         4.17</span></code></pre></div>
<p>Notice that the coefficient for <code>Fat</code> has decreased from 12.8 to 10.52 due to the influence of the Carbohydrate component.</p>
<!-- Correlation: linear relationship between two variables -->
<!-- Examples -->
<!-- Exercise / Q&A -->
<!-- Simple linear regression -->
<!-- Assumptions -->
<!-- Residuals: Observed - expected -->
<!-- Examples -->
<!-- Exercise / Q&A -->

</div>
</div>
<div class="footnotes">
<hr />
<ol start="11">
<li id="fn11"><p><code>lm</code> is short of linear model; this model is <em>linear</em> in the model coefficients.<a href="chapter6.html#fnref11">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter5.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter7.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/06-regression.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
